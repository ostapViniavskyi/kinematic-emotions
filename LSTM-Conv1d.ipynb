{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from torchsummary import summary\n",
    "\n",
    "from pymo.preprocessing import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionsMovementsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, records_path, transform_pipeline=None, fit_transform=False, signal_len=120):\n",
    "        records_path = Path(records_path)\n",
    "        self.root_path = records_path.parent\n",
    "        self.signals_list = pd.read_csv(records_path)   \n",
    "        self.transform_pipeline = transform_pipeline\n",
    "        self.signal_len=signal_len\n",
    "        \n",
    "        if self.transform_pipeline is not None and fit_transform:\n",
    "            self.__fit_transform_pipeline()\n",
    "        \n",
    "    def __fit_transform_pipeline(self):\n",
    "        data = [self.__getrawitem(i)[0] for i in range(len(self))]\n",
    "        self.transform_pipeline.fit(data)\n",
    "    \n",
    "    def __getrawitem(self, idx):\n",
    "        signal_metadata = self.signals_list.iloc[idx]\n",
    "        signal_id, signal_label = signal_metadata['id'], signal_metadata['label']\n",
    "        with open(Path(self.root_path, signal_id + '.pkl'), 'rb') as fd:\n",
    "            bvh_position = pickle.load(fd)\n",
    "        return bvh_position, signal_metadata['label']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.signals_list.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X, signal_label = self.__getrawitem(idx)\n",
    "\n",
    "        if self.transform_pipeline is not None:\n",
    "            X = self.transform_pipeline.transform([X])[0].astype(np.float32)\n",
    "            \n",
    "        X = X[-self.signal_len:, :] # get last signal_len timestemps\n",
    "        # pad if needed in the beginning\n",
    "        if X.shape[0] < self.signal_len:\n",
    "            X = np.pad(X, ((self.signal_len - X.shape[0], 0), (0, 0)), mode='edge')        \n",
    "        \n",
    "        return torch.from_numpy(X), signal_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform fitted!\n"
     ]
    }
   ],
   "source": [
    "transform_pipeline = Pipeline([\n",
    "    ('rcpn', RootCentricPositionNormalizer()),\n",
    "    ('delta', RootTransformer('abdolute_translation_deltas')),\n",
    "    ('const', ConstantsRemover()),\n",
    "#     ('selector', JointSelector(['Spine', 'RightFoot', 'LeftFoot', 'Head', 'RightForeArm', 'LeftForeArm'], include_root=True)),\n",
    "    ('np', Numpyfier()),\n",
    "    ('down', DownSampler(10)),\n",
    "    ('stdscale', ListStandardScaler())\n",
    "])\n",
    "\n",
    "train_ds = EmotionsMovementsDataset(\n",
    "    '/datasets/extra_space2/ostap/kinematic-dataset-of-actors-expressing-emotions-2.1.0/PyMO_output/train.csv',\n",
    "    transform_pipeline=transform_pipeline,\n",
    "    fit_transform=True\n",
    ")\n",
    "print('Transform fitted!')\n",
    "val_ds = EmotionsMovementsDataset(\n",
    "    '/datasets/extra_space2/ostap/kinematic-dataset-of-actors-expressing-emotions-2.1.0/PyMO_output/val.csv',\n",
    "    transform_pipeline=train_ds.transform_pipeline,\n",
    "    fit_transform=False\n",
    ")\n",
    "test_ds = EmotionsMovementsDataset(\n",
    "    '/datasets/extra_space2/ostap/kinematic-dataset-of-actors-expressing-emotions-2.1.0/PyMO_output/test.csv',\n",
    "    transform_pipeline=train_ds.transform_pipeline,\n",
    "    fit_transform=False\n",
    ")\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=10, shuffle=True, num_workers=10)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=10, shuffle=False, num_workers=10)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=10, shuffle=False, num_workers=10)\n",
    "X_sample = train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionLSTMBasic(nn.Module):\n",
    "    def __init__(self, input_size, lstm_hidden_size, fc_hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.lstm_layer = nn.LSTM(input_size, hidden_size=lstm_hidden_size, batch_first=True, num_layers=2)\n",
    "        self.fc = nn.Sequential(OrderedDict([\n",
    "            ('fc1', nn.Linear(lstm_hidden_size, fc_hidden_size)),\n",
    "            ('fc2', nn.Linear(fc_hidden_size, output_size))\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm_layer(x)\n",
    "        return self.fc(lstm_out[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmotionLSTMBasic(input_size=216, lstm_hidden_size=256, fc_hidden_size=512, output_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1679879"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(list(map(lambda x: x.numel(), list(model.parameters()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 120, 216])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(iter(train_dl))\n",
    "print(x[0].shape)\n",
    "model(x[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionConvBasic(nn.Module):\n",
    "    def __init__(self, in_channels, output_size):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.conv_layers = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv1d(in_channels, 256, kernel_size=3, padding=1, dilation=5)),\n",
    "            ('relu1', nn.ReLU(inplace=True)),\n",
    "            ('bn1', nn.BatchNorm1d(256)),\n",
    "            \n",
    "            ('conv2', nn.Conv1d(256, 256, kernel_size=3, padding=1, dilation=5)),\n",
    "            ('relu2', nn.ReLU(inplace=True)),\n",
    "            ('bn2', nn.BatchNorm1d(256)),\n",
    "            ('pool2', nn.MaxPool1d(kernel_size=2, stride=2)),\n",
    "            \n",
    "            ('conv3', nn.Conv1d(256, 512, kernel_size=3, padding=1, dilation=3)),\n",
    "            ('relu3', nn.ReLU(inplace=True)),\n",
    "            ('bn3', nn.BatchNorm1d(512)),\n",
    "            \n",
    "            ('conv6', nn.Conv1d(512, 512, kernel_size=3, padding=1, dilation=3)),\n",
    "            ('relu6', nn.ReLU(inplace=True)),\n",
    "            ('bn6', nn.BatchNorm1d(512)),\n",
    "            ('pool6', nn.MaxPool1d(kernel_size=2, stride=2)),\n",
    "        ]))\n",
    "        \n",
    "        self.fc = nn.Sequential(OrderedDict([\n",
    "            ('fc1', nn.Linear(512, 256)),\n",
    "            ('relu1', nn.ReLU(inplace=True)),\n",
    "#             ('fc2', nn.Linear(256, 256)),\n",
    "#             ('relu2', nn.ReLU(inplace=True)),\n",
    "            ('fc3', nn.Linear(256, self.output_size)),\n",
    "        ]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.mean(dim=2) # global average pooling\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmotionConvBasic(in_channels=216, output_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4cbbd0b92402>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m216\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/university/kinematic_emotions/venv/lib/python3.7/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/university/kinematic_emotions/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-fffb7cba3617>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/university/kinematic_emotions/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                 self._forward_hooks.values()):\n\u001b[0;32m--> 731\u001b[0;31m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/university/kinematic_emotions/venv/lib/python3.7/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36mhook\u001b[0;34m(module, input, output)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 summary[m_key][\"output_shape\"] = [\n\u001b[0;32m---> 23\u001b[0;31m                     \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 ]\n\u001b[1;32m     25\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/university/kinematic_emotions/venv/lib/python3.7/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 summary[m_key][\"output_shape\"] = [\n\u001b[0;32m---> 23\u001b[0;31m                     \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 ]\n\u001b[1;32m     25\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(120, 216), batch_size=10, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 120, 216])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 7])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(iter(train_dl))\n",
    "print(x[0].shape)\n",
    "model(x[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, test_dl, criterion, device):\n",
    "    model.eval()\n",
    "    batch_loss = []\n",
    "    samples, correct = 0, 0\n",
    "    for X_batch, y_batch in tqdm(test_dl):\n",
    "        batch_size = X_batch.shape[0]\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "        test_loss = criterion(y_pred, y_batch)\n",
    "        batch_loss.append(test_loss.item())\n",
    "\n",
    "        # evaluate accuracy\n",
    "        batch_correct = (torch.argmax(y_pred, dim=1) == y_batch).sum().item()\n",
    "        samples += batch_size\n",
    "        correct += batch_correct\n",
    "\n",
    "    \n",
    "    return np.mean(batch_loss), correct / samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dl, val_dl, epochs, criterion, optimizer, scheduler, path_to_model):\n",
    "\n",
    "    train_loss, val_loss = [], []\n",
    "    highest_val_accuracy = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        batch_train_loss = []\n",
    "\n",
    "        for X_batch, y_batch in tqdm(train_dl):\n",
    "            # perform single training step\n",
    "            model.zero_grad()\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            batch_train_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "            optimizer.step()\n",
    "        \n",
    "        epoch_train_loss = np.mean(batch_train_loss)\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        epoch_val_loss, val_accuracy = test(model, val_dl, criterion, device)\n",
    "        val_loss.append(epoch_val_loss)\n",
    "\n",
    "        if val_accuracy > highest_val_accuracy:\n",
    "            highest_val_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), path_to_model)\n",
    "            \n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, train loss: {epoch_train_loss}, val_loss: {epoch_val_loss},  val accu: {val_accuracy}\")\n",
    "\n",
    "    model.load_state_dict(torch.load(path_to_model))\n",
    "\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.14it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.76it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train loss: 2.4152120474193777, val_loss: 1.9449744383494059,  val accu: 0.2907801418439716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.98it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.97it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train loss: 1.8658920271056039, val_loss: 1.8010090033213297,  val accu: 0.28368794326241137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.03it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.90it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, train loss: 1.819962125803743, val_loss: 1.8212145725886026,  val accu: 0.24822695035460993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.96it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.73it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, train loss: 1.7748377482805933, val_loss: 1.7659835894902547,  val accu: 0.2907801418439716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.02it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.99it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, train loss: 1.7126298280698913, val_loss: 1.72534183661143,  val accu: 0.3120567375886525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.09it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.96it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, train loss: 1.7041612597448486, val_loss: 1.7790254751841228,  val accu: 0.3191489361702128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.06it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.84it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, train loss: 1.6801849997469358, val_loss: 1.7512413422266642,  val accu: 0.375886524822695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.07it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.79it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, train loss: 1.611825741827488, val_loss: 1.7533006111780802,  val accu: 0.3120567375886525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.03it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.79it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, train loss: 1.613161419651338, val_loss: 1.7457866986592612,  val accu: 0.3262411347517731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.05it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.93it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, train loss: 1.5718327185937337, val_loss: 1.761000680923462,  val accu: 0.375886524822695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.05it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.93it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, train loss: 1.4206962117127009, val_loss: 1.6471074581146241,  val accu: 0.4397163120567376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.05it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.92it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, train loss: 1.3471256670142924, val_loss: 1.6005613644917807,  val accu: 0.44680851063829785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.02it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.84it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, train loss: 1.325997841145311, val_loss: 1.6525244156519572,  val accu: 0.48936170212765956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.27it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.77it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, train loss: 1.2788052851600307, val_loss: 1.680016048749288,  val accu: 0.46808510638297873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.02it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.79it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, train loss: 1.260725581220218, val_loss: 1.5646246155103047,  val accu: 0.5035460992907801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.08it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.78it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, train loss: 1.1958361938595772, val_loss: 1.62852992216746,  val accu: 0.48936170212765956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.02it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.82it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, train loss: 1.1128955374338798, val_loss: 1.4612601240475973,  val accu: 0.5319148936170213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.06it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.83it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, train loss: 1.0933516131980079, val_loss: 1.666732366879781,  val accu: 0.5106382978723404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.99it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.79it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, train loss: 1.0555761376661914, val_loss: 1.46221821308136,  val accu: 0.5106382978723404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.90it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.77it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, train loss: 1.0152284636029176, val_loss: 1.5200376550356547,  val accu: 0.524822695035461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.99it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.77it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, train loss: 0.9094802292862109, val_loss: 1.3470430930455526,  val accu: 0.5531914893617021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.10it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.87it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, train loss: 0.8321650853114468, val_loss: 1.3858931223551432,  val accu: 0.5460992907801419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.08it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.73it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, train loss: 0.7488256495978151, val_loss: 1.4363008300463358,  val accu: 0.5460992907801419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.09it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.72it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, train loss: 0.7750872654308166, val_loss: 1.410248835881551,  val accu: 0.5390070921985816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.06it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.71it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, train loss: 0.7588408806228212, val_loss: 1.5048803051312765,  val accu: 0.5602836879432624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.05it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.83it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, train loss: 0.7225996843938317, val_loss: 1.4886307795842488,  val accu: 0.5319148936170213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.09it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.86it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, train loss: 0.7184035559850079, val_loss: 1.3993609388669332,  val accu: 0.5460992907801419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.07it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.82it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, train loss: 0.6841710551774928, val_loss: 1.4388020475705465,  val accu: 0.5602836879432624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.10it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.87it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, train loss: 0.6207400126648801, val_loss: 1.5932814399401347,  val accu: 0.5319148936170213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.15it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, train loss: 0.5979338133308504, val_loss: 1.582283572355906,  val accu: 0.5531914893617021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2.4152120474193777,\n",
       "  1.8658920271056039,\n",
       "  1.819962125803743,\n",
       "  1.7748377482805933,\n",
       "  1.7126298280698913,\n",
       "  1.7041612597448486,\n",
       "  1.6801849997469358,\n",
       "  1.611825741827488,\n",
       "  1.613161419651338,\n",
       "  1.5718327185937337,\n",
       "  1.4206962117127009,\n",
       "  1.3471256670142924,\n",
       "  1.325997841145311,\n",
       "  1.2788052851600307,\n",
       "  1.260725581220218,\n",
       "  1.1958361938595772,\n",
       "  1.1128955374338798,\n",
       "  1.0933516131980079,\n",
       "  1.0555761376661914,\n",
       "  1.0152284636029176,\n",
       "  0.9094802292862109,\n",
       "  0.8321650853114468,\n",
       "  0.7488256495978151,\n",
       "  0.7750872654308166,\n",
       "  0.7588408806228212,\n",
       "  0.7225996843938317,\n",
       "  0.7184035559850079,\n",
       "  0.6841710551774928,\n",
       "  0.6207400126648801,\n",
       "  0.5979338133308504],\n",
       " [1.9449744383494059,\n",
       "  1.8010090033213297,\n",
       "  1.8212145725886026,\n",
       "  1.7659835894902547,\n",
       "  1.72534183661143,\n",
       "  1.7790254751841228,\n",
       "  1.7512413422266642,\n",
       "  1.7533006111780802,\n",
       "  1.7457866986592612,\n",
       "  1.761000680923462,\n",
       "  1.6471074581146241,\n",
       "  1.6005613644917807,\n",
       "  1.6525244156519572,\n",
       "  1.680016048749288,\n",
       "  1.5646246155103047,\n",
       "  1.62852992216746,\n",
       "  1.4612601240475973,\n",
       "  1.666732366879781,\n",
       "  1.46221821308136,\n",
       "  1.5200376550356547,\n",
       "  1.3470430930455526,\n",
       "  1.3858931223551432,\n",
       "  1.4363008300463358,\n",
       "  1.410248835881551,\n",
       "  1.5048803051312765,\n",
       "  1.4886307795842488,\n",
       "  1.3993609388669332,\n",
       "  1.4388020475705465,\n",
       "  1.5932814399401347,\n",
       "  1.582283572355906])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(\n",
    "    model,\n",
    "    train_dl, \n",
    "    val_dl,\n",
    "    epochs=30,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    path_to_model='model_conv_dilation9_9_5_3.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:02<00:00,  5.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.4089144455889862, 0.6028368794326241)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('model_conv_dilation5_3.pth')\n",
    "model.load_state_dict(state_dict)\n",
    "test(model, test_dl, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:03<00:00,  4.99it/s]\n"
     ]
    }
   ],
   "source": [
    "y_true_all, y_pred_all = [], []\n",
    "for X, y_true in tqdm(test_dl):\n",
    "    y_pred = model(X.to(device))\n",
    "    y_pred = y_pred.argmax(dim=1)\n",
    "    y_true_all.extend(y_true.tolist())\n",
    "    y_pred_all.extend(y_pred.tolist())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from seaborn import heatmap, barplot, histplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['A', 'D', 'F', 'H', 'N', 'SA', 'SU'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_idx = {'A': 0, 'D': 1, 'F': 2, 'H': 3, 'N': 4, 'SA': 5, 'SU': 6}\n",
    "idx_to_label = {v:k for k,v in labels_to_idx.items()}\n",
    "idx_to_label.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true_all, y_pred_all)\n",
    "\n",
    "plt.figure(figsize=(8, 7))\n",
    "heatmap(cm, annot=True, xticklabels=idx_to_label.values(), yticklabels=idx_to_label.values())\n",
    "plt.xlabel('Pred')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "histplot(y_true_all, bins=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
