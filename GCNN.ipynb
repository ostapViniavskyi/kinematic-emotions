{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from torchsummary import summary\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "\n",
    "from pymo.preprocessing import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionsMovementsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, records_path, transform_pipeline=None, fit_transform=False, signal_len=120):\n",
    "        records_path = Path(records_path)\n",
    "        self.root_path = records_path.parent\n",
    "        self.signals_list = pd.read_csv(records_path)   \n",
    "        self.transform_pipeline = transform_pipeline\n",
    "        self.signal_len=signal_len\n",
    "        \n",
    "        if self.transform_pipeline is not None and fit_transform:\n",
    "            self.__fit_transform_pipeline()\n",
    "        \n",
    "    def __fit_transform_pipeline(self):\n",
    "        data = [self.__getrawitem(i)[0] for i in range(len(self))]\n",
    "        self.transform_pipeline.fit(data)\n",
    "    \n",
    "    def __getrawitem(self, idx):\n",
    "        signal_metadata = self.signals_list.iloc[idx]\n",
    "        signal_id, signal_label = signal_metadata['id'], signal_metadata['label']\n",
    "        with open(Path(self.root_path, signal_id + '.pkl'), 'rb') as fd:\n",
    "            bvh_position = pickle.load(fd)\n",
    "        return bvh_position, signal_metadata['label']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.signals_list.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X, signal_label = self.__getrawitem(idx)\n",
    "\n",
    "        if self.transform_pipeline is not None:\n",
    "            X = self.transform_pipeline.transform([X])[0].astype(np.float32)\n",
    "            \n",
    "        X = X[-self.signal_len:, :] # get last signal_len timestemps\n",
    "        # pad if needed in the beginning\n",
    "        if X.shape[0] < self.signal_len:\n",
    "            X = np.pad(X, ((self.signal_len - X.shape[0], 0), (0, 0)), mode='edge')        \n",
    "        \n",
    "        return torch.from_numpy(X), signal_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform fitted!\n"
     ]
    }
   ],
   "source": [
    "transform_pipeline = Pipeline([\n",
    "    ('rcpn', RootCentricPositionNormalizer()),\n",
    "    ('delta', RootTransformer('abdolute_translation_deltas')),\n",
    "    ('const', ConstantsRemover()),\n",
    "#     ('selector', JointSelector(['Spine', 'RightFoot', 'LeftFoot', 'Head', 'RightForeArm', 'LeftForeArm'], include_root=True)),\n",
    "    ('np', Numpyfier()),\n",
    "    ('down', DownSampler(10)),\n",
    "    ('stdscale', ListStandardScaler())\n",
    "])\n",
    "\n",
    "train_ds = EmotionsMovementsDataset(\n",
    "    '/datasets/extra_space2/ostap/kinematic-dataset-of-actors-expressing-emotions-2.1.0/PyMO_output/train.csv',\n",
    "    transform_pipeline=transform_pipeline,\n",
    "    fit_transform=True,\n",
    "    signal_len=120\n",
    ")\n",
    "print('Transform fitted!')\n",
    "val_ds = EmotionsMovementsDataset(\n",
    "    '/datasets/extra_space2/ostap/kinematic-dataset-of-actors-expressing-emotions-2.1.0/PyMO_output/val.csv',\n",
    "    transform_pipeline=train_ds.transform_pipeline,\n",
    "    fit_transform=False,\n",
    "    signal_len=120\n",
    ")\n",
    "test_ds = EmotionsMovementsDataset(\n",
    "    '/datasets/extra_space2/ostap/kinematic-dataset-of-actors-expressing-emotions-2.1.0/PyMO_output/test.csv',\n",
    "    transform_pipeline=train_ds.transform_pipeline,\n",
    "    fit_transform=False,\n",
    "    signal_len=120\n",
    ")\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=10, shuffle=True, num_workers=10)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=10, shuffle=False, num_workers=10)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=10, shuffle=False, num_workers=10)\n",
    "X_sample = train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pymo.data.MocapData at 0x7f202c72cdd0>]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mocap_data, _ = train_ds._EmotionsMovementsDataset__getrawitem(0)\n",
    "mocap_data = [mocap_data]\n",
    "for _, transform_step in train_ds.transform_pipeline.steps[:-3]:\n",
    "    mocap_data = transform_step.transform(mocap_data)\n",
    "mocap_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjacency_matrix(mocap_data, num_channels=3):\n",
    "    nodes_num = mocap_data.values.shape[1] // num_channels    \n",
    "    # assign nodes numbers\n",
    "    used_nodes = {}\n",
    "    for i, name in enumerate(mocap_data.values.columns):\n",
    "        node_name = '_'.join(name.split('_')[:-1])\n",
    "        if node_name not in used_nodes:\n",
    "            used_nodes[node_name] = i // num_channels\n",
    "        else:\n",
    "            assert used_nodes[node_name] == i // num_channels\n",
    "    \n",
    "    # construct adj. matrix\n",
    "    A = np.zeros((nodes_num, nodes_num))\n",
    "    for node_name, props in mocap_data.skeleton.items():\n",
    "        parent = props['parent']\n",
    "        if parent is None:\n",
    "            continue\n",
    "        node_idx, parent_idx = used_nodes[node_name], used_nodes[parent]\n",
    "        A[node_idx, parent_idx] = 1\n",
    "        A[parent_idx, node_idx] = 1\n",
    "        \n",
    "    return A\n",
    "\n",
    "A = get_adjacency_matrix(mocap_data[0], num_channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_fourway = ((A + A@A + A@A@A + A@A@A@A) > 0).astype(np.int64) - np.eye(A.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvLayer(nn.Module):\n",
    "    def __init__(self, A, in_channels, out_channels, add_identity=True, aggregation='sum'):\n",
    "        super().__init__()\n",
    "        A = torch.FloatTensor(A)\n",
    "        if add_identity:\n",
    "            A = A + torch.eye(A.size(0))\n",
    "            \n",
    "        if aggregation == 'sum':\n",
    "            pass\n",
    "        elif aggregation == 'mean':\n",
    "            d = 1 / torch.sum(A, dim=1)\n",
    "            A = A * d.unsqueeze(-1)\n",
    "        elif aggregation == 'spectral':\n",
    "            d = 1 / torch.sqrt(torch.sum(A, dim=1))\n",
    "            A = A * d * d.unsqueeze(-1)\n",
    "        else:\n",
    "            raise ValueError(f'Wrong aggregation method provided! ({aggregation})')\n",
    "            \n",
    "        self.register_buffer('aggregation_matrix', A) \n",
    "        self.linear = nn.Linear(in_channels, out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        *batch_size, nodes_num, feature_size = x.size()\n",
    "        x = torch.matmul(self.aggregation_matrix, x)\n",
    "        x = x.view(-1, feature_size)\n",
    "        x = self.linear(x)\n",
    "        x = x.view(*batch_size, nodes_num, -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0]\n",
    "])\n",
    "\n",
    "gcl = GraphConvLayer(a, in_channels=4, out_channels=10, aggregation='spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150, 10, 3, 10])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(150, 10, 3, 4)\n",
    "gcl(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionConvBasic(nn.Module):\n",
    "    def __init__(self, in_channels, output_size):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.conv_layers = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv1d(in_channels, 256, kernel_size=3, padding=1, dilation=5)),\n",
    "            ('relu1', nn.ReLU(inplace=True)),\n",
    "            ('bn1', nn.BatchNorm1d(256)),\n",
    "            \n",
    "            ('conv2', nn.Conv1d(256, 256, kernel_size=3, padding=1, dilation=5)),\n",
    "            ('relu2', nn.ReLU(inplace=True)),\n",
    "            ('bn2', nn.BatchNorm1d(256)),\n",
    "            ('pool2', nn.MaxPool1d(kernel_size=2, stride=2)),\n",
    "            \n",
    "            ('conv3', nn.Conv1d(256, 512, kernel_size=3, padding=1, dilation=3)),\n",
    "            ('relu3', nn.ReLU(inplace=True)),\n",
    "            ('bn3', nn.BatchNorm1d(512)),\n",
    "            \n",
    "            ('conv6', nn.Conv1d(512, 512, kernel_size=3, padding=1, dilation=3)),\n",
    "            ('relu6', nn.ReLU(inplace=True)),\n",
    "            ('bn6', nn.BatchNorm1d(512)),\n",
    "            ('pool6', nn.MaxPool1d(kernel_size=2, stride=2)),\n",
    "        ]))\n",
    "        \n",
    "        self.fc = nn.Sequential(OrderedDict([\n",
    "            ('fc1', nn.Linear(512, 256)),\n",
    "            ('relu1', nn.ReLU(inplace=True)),\n",
    "#             ('fc2', nn.Linear(256, 256)),\n",
    "#             ('relu2', nn.ReLU(inplace=True)),\n",
    "            ('fc3', nn.Linear(256, self.output_size)),\n",
    "        ]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.mean(dim=2) # global average pooling\n",
    "        return self.fc(x)\n",
    "\n",
    "class GemotionNet(nn.Module):\n",
    "    def __init__(self, A, in_channels, nodes_num, output_size):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.nodes_num = nodes_num\n",
    "        self.output_size = output_size\n",
    "        self.gcnn = nn.Sequential(OrderedDict([\n",
    "            ('gconv1', GraphConvLayer(A, in_channels, 16, add_identity=True, aggregation='spectral')),\n",
    "            ('relu1', nn.ReLU(inplace=True)),\n",
    "            ('gconv2', GraphConvLayer(A, 16, 32, add_identity=True, aggregation='spectral')),\n",
    "            ('relu2', nn.ReLU(inplace=True)),\n",
    "#             ('gconv3', GraphConvLayer(A, 32, 64, add_identity=True, aggregation='spectral')),\n",
    "#             ('relu3', nn.ReLU(inplace=True)),\n",
    "#             ('gconv4', GraphConvLayer(A, 64, 128, add_identity=True, aggregation='spectral')),\n",
    "#             ('relu4', nn.ReLU(inplace=True)),\n",
    "        ]))\n",
    "        \n",
    "        self.conv_classifier = EmotionConvBasic(in_channels=32*nodes_num, output_size=output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, c = x.size()\n",
    "        x = x.view(batch_size, seq_len, -1, self.in_channels)\n",
    "        x = self.gcnn(x)\n",
    "        x = x.view(batch_size, seq_len, -1)\n",
    "        x = self.conv_classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 120, 216])\n",
      "torch.Size([10, 7])\n"
     ]
    }
   ],
   "source": [
    "model = GemotionNet(A=A_fourway, in_channels=3, nodes_num=72, output_size=7)\n",
    "X = next(iter(train_dl))[0]\n",
    "print(X.shape)\n",
    "print(model(X).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [10, 16]              64\n",
      "    GraphConvLayer-2          [10, 240, 72, 16]               0\n",
      "              ReLU-3          [10, 240, 72, 16]               0\n",
      "            Linear-4                   [10, 32]             544\n",
      "    GraphConvLayer-5          [10, 240, 72, 32]               0\n",
      "              ReLU-6          [10, 240, 72, 32]               0\n",
      "            Conv1d-7             [10, 256, 232]       1,769,728\n",
      "              ReLU-8             [10, 256, 232]               0\n",
      "       BatchNorm1d-9             [10, 256, 232]             512\n",
      "           Conv1d-10             [10, 256, 224]         196,864\n",
      "             ReLU-11             [10, 256, 224]               0\n",
      "      BatchNorm1d-12             [10, 256, 224]             512\n",
      "        MaxPool1d-13             [10, 256, 112]               0\n",
      "           Conv1d-14             [10, 512, 108]         393,728\n",
      "             ReLU-15             [10, 512, 108]               0\n",
      "      BatchNorm1d-16             [10, 512, 108]           1,024\n",
      "           Conv1d-17             [10, 512, 104]         786,944\n",
      "             ReLU-18             [10, 512, 104]               0\n",
      "      BatchNorm1d-19             [10, 512, 104]           1,024\n",
      "        MaxPool1d-20              [10, 512, 52]               0\n",
      "           Linear-21                  [10, 256]         131,328\n",
      "             ReLU-22                  [10, 256]               0\n",
      "           Linear-23                    [10, 7]           1,799\n",
      " EmotionConvBasic-24                    [10, 7]               0\n",
      "================================================================\n",
      "Total params: 3,284,071\n",
      "Trainable params: 3,284,071\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.98\n",
      "Forward/backward pass size (MB): 182.39\n",
      "Params size (MB): 12.53\n",
      "Estimated Total Size (MB): 196.89\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(240, 216), batch_size=10, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2')\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, test_dl, criterion, device):\n",
    "    model.eval()\n",
    "    batch_loss = []\n",
    "    samples, correct = 0, 0\n",
    "    for X_batch, y_batch in tqdm(test_dl):\n",
    "        batch_size = X_batch.shape[0]\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "        test_loss = criterion(y_pred, y_batch)\n",
    "        batch_loss.append(test_loss.item())\n",
    "\n",
    "        # evaluate accuracy\n",
    "        batch_correct = (torch.argmax(y_pred, dim=1) == y_batch).sum().item()\n",
    "        samples += batch_size\n",
    "        correct += batch_correct\n",
    "\n",
    "    \n",
    "    return np.mean(batch_loss), correct / samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dl, val_dl, epochs, criterion, optimizer, scheduler, path_to_model):\n",
    "\n",
    "    train_loss, val_loss = [], []\n",
    "    highest_val_accuracy = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        batch_train_loss = []\n",
    "\n",
    "        for X_batch, y_batch in tqdm(train_dl):\n",
    "            # perform single training step\n",
    "            model.zero_grad()\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            batch_train_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "            optimizer.step()\n",
    "        \n",
    "        epoch_train_loss = np.mean(batch_train_loss)\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        epoch_val_loss, val_accuracy = test(model, val_dl, criterion, device)\n",
    "        val_loss.append(epoch_val_loss)\n",
    "\n",
    "        if val_accuracy > highest_val_accuracy:\n",
    "            highest_val_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), path_to_model)\n",
    "            \n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, train loss: {epoch_train_loss}, val_loss: {epoch_val_loss},  val accu: {val_accuracy}\")\n",
    "\n",
    "    model.load_state_dict(torch.load(path_to_model))\n",
    "\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.30it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.23it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train loss: 2.0961657113262584, val_loss: 1.8353211561838785,  val accu: 0.2978723404255319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.47it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.26it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train loss: 1.8605482376047544, val_loss: 1.8068360487620037,  val accu: 0.20567375886524822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.33it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.14it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, train loss: 1.8035896505628313, val_loss: 1.8676209767659506,  val accu: 0.3120567375886525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.32it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.25it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, train loss: 1.6734639507319247, val_loss: 1.8201829671859742,  val accu: 0.3049645390070922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.60it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.24it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, train loss: 1.6237971750753266, val_loss: 1.7844235976537068,  val accu: 0.41134751773049644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.56it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.31it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, train loss: 1.5543711898582322, val_loss: 1.792241390546163,  val accu: 0.3404255319148936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.25it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.87it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, train loss: 1.4858579635620117, val_loss: 1.5691613992055258,  val accu: 0.45390070921985815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.53it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.18it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, train loss: 1.4692989949669157, val_loss: 1.786903691291809,  val accu: 0.4397163120567376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.40it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.26it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, train loss: 1.4549432529934816, val_loss: 3.502985644340515,  val accu: 0.375886524822695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.82it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.02it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, train loss: 1.3748791201838426, val_loss: 1.687197756767273,  val accu: 0.48936170212765956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.27it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.25it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, train loss: 1.231896805443934, val_loss: 1.6025867462158203,  val accu: 0.48936170212765956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.37it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.28it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, train loss: 1.1065124746944224, val_loss: 1.478904871145884,  val accu: 0.5177304964539007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.53it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.27it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, train loss: 1.069288773196084, val_loss: 1.5143625736236572,  val accu: 0.5106382978723404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.48it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.82it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, train loss: 1.0831147908632244, val_loss: 1.438617726167043,  val accu: 0.5177304964539007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.39it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.19it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, train loss: 0.9931314329483679, val_loss: 1.4879401723543804,  val accu: 0.5390070921985816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.46it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.26it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, train loss: 0.9607512088758605, val_loss: 1.5306195457776388,  val accu: 0.49645390070921985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.36it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.29it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, train loss: 0.9133878986218146, val_loss: 1.9233631094296773,  val accu: 0.5319148936170213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.28it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.20it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, train loss: 0.9045513737946749, val_loss: 1.3708146850268046,  val accu: 0.5886524822695035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.55it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.24it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, train loss: 0.8692178907138961, val_loss: 1.6394891083240508,  val accu: 0.5602836879432624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.45it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.23it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, train loss: 0.812615932364549, val_loss: 1.5259201486905416,  val accu: 0.5602836879432624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.50it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.16it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, train loss: 0.6707865675645215, val_loss: 1.2280643542607625,  val accu: 0.6099290780141844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.38it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.25it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, train loss: 0.6110116932541132, val_loss: 1.4290363868077596,  val accu: 0.5602836879432624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.41it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.17it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, train loss: 0.595685469917953, val_loss: 1.3442461768786111,  val accu: 0.5815602836879432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.61it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.97it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, train loss: 0.5484365807580096, val_loss: 1.5027197519938151,  val accu: 0.5815602836879432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.74it/s]\n",
      "100%|██████████| 15/15 [00:04<00:00,  3.55it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, train loss: 0.5032103631778487, val_loss: 1.5199601769447326,  val accu: 0.6382978723404256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.39it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.22it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, train loss: 0.4854700953167464, val_loss: 1.4679800768693287,  val accu: 0.6028368794326241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.47it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.87it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, train loss: 0.4818705047613808, val_loss: 1.796922250588735,  val accu: 0.5957446808510638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.63it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.26it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, train loss: 0.4498462660703808, val_loss: 1.3927305420239766,  val accu: 0.6099290780141844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.20it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.13it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, train loss: 0.4183904842939228, val_loss: 1.4264478345712026,  val accu: 0.5957446808510638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.54it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.16it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, train loss: 0.41729003257517305, val_loss: 1.4206987738609314,  val accu: 0.5815602836879432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.55it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.21it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, train loss: 0.36143442832066547, val_loss: 1.2974597692489624,  val accu: 0.6028368794326241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.50it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.35it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, train loss: 0.351607298212392, val_loss: 1.328938865661621,  val accu: 0.6028368794326241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.22it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.15it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, train loss: 0.3203560492090349, val_loss: 1.6612290958563487,  val accu: 0.574468085106383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.21it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, train loss: 0.3407188397832215, val_loss: 1.4343315839767456,  val accu: 0.6028368794326241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.47it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.13it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, train loss: 0.32762463527199415, val_loss: 2.685870385169983,  val accu: 0.5602836879432624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.84it/s]\n",
      "100%|██████████| 15/15 [00:04<00:00,  3.62it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, train loss: 0.2955613041662478, val_loss: 1.4230066061019897,  val accu: 0.5957446808510638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.38it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.22it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, train loss: 0.2926866502966732, val_loss: 1.4717220703760783,  val accu: 0.5815602836879432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.36it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.22it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, train loss: 0.3197147900105587, val_loss: 1.3799875617027282,  val accu: 0.5815602836879432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.61it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.26it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, train loss: 0.2939815191285951, val_loss: 1.4750437517960866,  val accu: 0.574468085106383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.32it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.12it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, train loss: 0.26527397271378766, val_loss: 1.494576229651769,  val accu: 0.5957446808510638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.57it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.09it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, train loss: 0.25688387994055767, val_loss: 1.6777040640513101,  val accu: 0.5815602836879432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.56it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.17it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, train loss: 0.23750947304402611, val_loss: 1.5066017627716064,  val accu: 0.5886524822695035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.44it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.39it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, train loss: 0.25762721204331945, val_loss: 1.6281474828720093,  val accu: 0.5957446808510638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.30it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.85it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, train loss: 0.2659640948487712, val_loss: 1.5083961288134258,  val accu: 0.6028368794326241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.40it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.12it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, train loss: 0.25047698710113764, val_loss: 1.9132433633009593,  val accu: 0.5886524822695035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.53it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.11it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, train loss: 0.24003713341828967, val_loss: 1.5016451597213745,  val accu: 0.5957446808510638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.79it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.97it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, train loss: 0.24839452546023363, val_loss: 1.463441757361094,  val accu: 0.574468085106383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.24it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.21it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, train loss: 0.24901841118532633, val_loss: 1.466358075539271,  val accu: 0.5886524822695035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:15<00:00,  7.36it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.07it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, train loss: 0.2456886068768134, val_loss: 1.4460155924161275,  val accu: 0.6099290780141844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:14<00:00,  7.63it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, train loss: 0.2567216764270727, val_loss: 2.297782242298126,  val accu: 0.5815602836879432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2.0961657113262584,\n",
       "  1.8605482376047544,\n",
       "  1.8035896505628313,\n",
       "  1.6734639507319247,\n",
       "  1.6237971750753266,\n",
       "  1.5543711898582322,\n",
       "  1.4858579635620117,\n",
       "  1.4692989949669157,\n",
       "  1.4549432529934816,\n",
       "  1.3748791201838426,\n",
       "  1.231896805443934,\n",
       "  1.1065124746944224,\n",
       "  1.069288773196084,\n",
       "  1.0831147908632244,\n",
       "  0.9931314329483679,\n",
       "  0.9607512088758605,\n",
       "  0.9133878986218146,\n",
       "  0.9045513737946749,\n",
       "  0.8692178907138961,\n",
       "  0.812615932364549,\n",
       "  0.6707865675645215,\n",
       "  0.6110116932541132,\n",
       "  0.595685469917953,\n",
       "  0.5484365807580096,\n",
       "  0.5032103631778487,\n",
       "  0.4854700953167464,\n",
       "  0.4818705047613808,\n",
       "  0.4498462660703808,\n",
       "  0.4183904842939228,\n",
       "  0.41729003257517305,\n",
       "  0.36143442832066547,\n",
       "  0.351607298212392,\n",
       "  0.3203560492090349,\n",
       "  0.3407188397832215,\n",
       "  0.32762463527199415,\n",
       "  0.2955613041662478,\n",
       "  0.2926866502966732,\n",
       "  0.3197147900105587,\n",
       "  0.2939815191285951,\n",
       "  0.26527397271378766,\n",
       "  0.25688387994055767,\n",
       "  0.23750947304402611,\n",
       "  0.25762721204331945,\n",
       "  0.2659640948487712,\n",
       "  0.25047698710113764,\n",
       "  0.24003713341828967,\n",
       "  0.24839452546023363,\n",
       "  0.24901841118532633,\n",
       "  0.2456886068768134,\n",
       "  0.2567216764270727],\n",
       " [1.8353211561838785,\n",
       "  1.8068360487620037,\n",
       "  1.8676209767659506,\n",
       "  1.8201829671859742,\n",
       "  1.7844235976537068,\n",
       "  1.792241390546163,\n",
       "  1.5691613992055258,\n",
       "  1.786903691291809,\n",
       "  3.502985644340515,\n",
       "  1.687197756767273,\n",
       "  1.6025867462158203,\n",
       "  1.478904871145884,\n",
       "  1.5143625736236572,\n",
       "  1.438617726167043,\n",
       "  1.4879401723543804,\n",
       "  1.5306195457776388,\n",
       "  1.9233631094296773,\n",
       "  1.3708146850268046,\n",
       "  1.6394891083240508,\n",
       "  1.5259201486905416,\n",
       "  1.2280643542607625,\n",
       "  1.4290363868077596,\n",
       "  1.3442461768786111,\n",
       "  1.5027197519938151,\n",
       "  1.5199601769447326,\n",
       "  1.4679800768693287,\n",
       "  1.796922250588735,\n",
       "  1.3927305420239766,\n",
       "  1.4264478345712026,\n",
       "  1.4206987738609314,\n",
       "  1.2974597692489624,\n",
       "  1.328938865661621,\n",
       "  1.6612290958563487,\n",
       "  1.4343315839767456,\n",
       "  2.685870385169983,\n",
       "  1.4230066061019897,\n",
       "  1.4717220703760783,\n",
       "  1.3799875617027282,\n",
       "  1.4750437517960866,\n",
       "  1.494576229651769,\n",
       "  1.6777040640513101,\n",
       "  1.5066017627716064,\n",
       "  1.6281474828720093,\n",
       "  1.5083961288134258,\n",
       "  1.9132433633009593,\n",
       "  1.5016451597213745,\n",
       "  1.463441757361094,\n",
       "  1.466358075539271,\n",
       "  1.4460155924161275,\n",
       "  2.297782242298126])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(\n",
    "    model,\n",
    "    train_dl, \n",
    "    val_dl,\n",
    "    epochs=50,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    path_to_model='model_gcnn.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:03<00:00,  4.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.5051753640174867, 0.5531914893617021)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('model_gcnn.pth')\n",
    "model.load_state_dict(state_dict)\n",
    "test(model, test_dl, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:03<00:00,  4.99it/s]\n"
     ]
    }
   ],
   "source": [
    "y_true_all, y_pred_all = [], []\n",
    "for X, y_true in tqdm(test_dl):\n",
    "    y_pred = model(X.to(device))\n",
    "    y_pred = y_pred.argmax(dim=1)\n",
    "    y_true_all.extend(y_true.tolist())\n",
    "    y_pred_all.extend(y_pred.tolist())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from seaborn import heatmap, barplot, histplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['A', 'D', 'F', 'H', 'N', 'SA', 'SU'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_idx = {'A': 0, 'D': 1, 'F': 2, 'H': 3, 'N': 4, 'SA': 5, 'SU': 6}\n",
    "idx_to_label = {v:k for k,v in labels_to_idx.items()}\n",
    "idx_to_label.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc8AAAG5CAYAAADoA7/3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA1Y0lEQVR4nO3deZxT5dn/8c81C8ugoIiILIotolg3FKhLtShudUOrQqlYbeuPLtaidWlrrUvr9rigIopFXBAFpWJVhKeiPgryuBSkqCw6giDCgIiCKMMyy/X7I4GOPMDMySS5c5Lv21deTk6Sc76HJHPNfZ07J+buiIiISMMVhQ4gIiISNyqeIiIiEal4ioiIRKTiKSIiEpGKp4iISEQqniIiIhGpeErBMbPmZjbBzL40s783Yj3nmtnkdGYLxcyOMrMPQucQiQvT5zwlV5nZj4HfAfsCXwGzgBvdfVoj13secDFwhLtXNzZnrjMzB/Z29/mhs4jkC408JSeZ2e+Au4CbgN2APYD7gL5pWP2eQHkhFM6GMLOS0BlE4kbFU3KOmbUC/gJc5O5Pu/tad69y9wnufkXyPk3N7C4zq0he7jKzpsnbepvZEjO7zMxWmNkyM/tp8rbrgWuA/mb2tZn93MyuM7PH6my/s5n5pqJiZheY2Udm9pWZLTSzc+ssn1bncUeY2fRkO3i6mR1R57ZXzeyvZva/yfVMNrM229j/TfmvrJP/DDM72czKzewLM7uqzv17mdkbZrY6ed9hZtYkedvU5N3eSe5v/zrr/72ZLQce3rQs+ZhvJ7dxSPJ6ezP7zMx6N+Z5FcknKp6Siw4HmgH/2M59/gQcBhwMHAT0Aq6uc3s7oBXQAfg5cK+Z7ezu15IYzT7p7ju4+4PbC2JmLYChwA/cfUfgCBLt4y3v1xqYmLzvLsAQYKKZ7VLnbj8Gfgq0BZoAl29n0+1I/Bt0IFHsHwAGAocCRwF/NrO9kvetAS4F2pD4t+sD/BrA3Y9O3ueg5P4+WWf9rUmMwgfV3bC7LwB+DzxmZmXAw8Aod391O3lFCoqKp+SiXYCV9bRVzwX+4u4r3P0z4HrgvDq3VyVvr3L3ScDXwD4p5qkF9jez5u6+zN3nbOU+pwAfuvtod69297HA+8Bpde7zsLuXu/s6YByJwr8tVSSO71YBT5AojHe7+1fJ7c8l8UcD7v62u7+Z3O4i4G/A9xuwT9e6+4Zknm9w9weA+cBbwO4k/lgRkSQVT8lFnwNt6jkW1x74uM71j5PLNq9ji+JbCewQNYi7rwX6A78ElpnZRDPbtwF5NmXqUOf68gh5Pnf3muTPm4rbp3VuX7fp8WbW1cyeN7PlZraGxMh6qy3hOj5z9/X13OcBYH/gHnffUM99RQqKiqfkojeADcAZ27lPBYmW4yZ7JJelYi1QVud6u7o3uvsL7n48iRHY+ySKSn15NmVammKmKIaTyLW3u7cErgKsnsdsd5q9me1AYsLWg8B1yba0iCSpeErOcfcvSRznuzc5UabMzErN7AdmdmvybmOBq81s1+TEm2uAx7a1znrMAo42sz2Sk5X+uOkGM9vNzPomj31uINH+rd3KOiYBXc3sx2ZWYmb9gf2A51PMFMWOwBrg6+So+Fdb3P4p8K2I67wbmOHuF5I4lnt/o1OK5BEVT8lJ7n4Hic94Xg18BnwC/AZ4JnmXG4AZwLvAe8DM5LJUtvUi8GRyXW/zzYJXlMxRAXxB4ljilsUJd/8cOBW4jETb+UrgVHdfmUqmiC4nMRnpKxKj4ie3uP06YFRyNm6/+lZmZn2Bk/jPfv4OOGTTLGMR0UkSREREItPIU0REJCIVTxERkYhUPEVERCJS8RQREYkoZ08IXbXyo7yZydS8/VGhI6RNm7KWoSPIVqysXBM6Qtrk02ssn56X6o1L6/vscMrS+fu+tM23MpazLo08RUREIsrZkaeIiBSI2pr675NjNPIUERGJSCNPEREJy7d2xsvcpuIpIiJh1caveKptKyIiEpFGniIiEpSrbSsiIhKR2rYiIiL5TyNPEREJS21bERGRiHSSBBERkfynkaeIiISltq2IiEhEmm0rIiKS/zTyFBGRoHSSBBERkajUthUREcl/GnmKiEhYMWzbauQpIiJh1dak71IPM3vIzFaY2ewtll9sZu+b2Rwzu7W+9ah4iohIIXkEOKnuAjM7BugLHOTu3wFur28latuKiEhYWWzbuvtUM+u8xeJfAbe4+4bkfVbUt56CGXlefdMQjj7lR5wx8Jebl13255s56/yLOOv8izjhrPM56/yLAiZM3Ykn9GbO7Km8P3caV14Rz33Y5M5hNzD7w2m8+vpzoaM0Wj7ti15juSlvnpfa2rRdzGyQmc2ocxnUgARdgaPM7C0zm2JmPet7QMEUzzNOPp77h9zwjWV3/PWPjB91L+NH3cvxvb/Hcd8/IlC61BUVFTH07hs59bSBHHDQMfTvfwbduu0dOlbKnhzzDAPObshrPffly77oNZab8u15SRd3H+HuPepcRjTgYSVAa+Aw4ApgnJnZ9h6QteJpZt8zs3uztb0t9Tj4AFq13HGrt7k7//yfqZx8fO/shkqDXj27s2DBIhYuXExVVRXjxj3L6aedGDpWyt58fQarV60OHSMt8mVf9BrLTXn1vHht+i6pWQI87Qn/AmqBNtt7QEaLp5l1N7PbzGwR8Ffg/UxuL1VvvzObXXbemT07dQgdJbL2HdrxyZKKzdeXLF1G+/btAiaSfKPXWG7Kq+cljW3bFD0DHANgZl2BJsDK7T0g7cXTzLqa2bVm9j5wD7AYMHc/xt3vqeexm3vVIx8dm+5o2zTpxVc5+fjvZ217IiIShpmNBd4A9jGzJWb2c+Ah4FvJj688AZzv7r699WRitu37wGvAqe4+Pxn20oY8MNmbHgFQtfKj7QZPl+rqGl6a8jrjHhqajc2lXcXS5XTq2H7z9Y4ddqeiYnnARJJv9BrLTfn0vLhn78uw3X3ANm4aGGU9mWjb/hBYBrxiZg+YWR9guwdeQ3pzxr/51p4dadd219BRUjJ9xiy6dNmLzp07UVpaSr9+fZnw/OTQsSSP6DWWm/LqeQl/zDOytBdPd3/G3X8E7Au8AlwCtDWz4WZ2Qrq311BXXHsL5/7iUhYtXkKfMwYyfsILAPz3S1P4wXG9Q8VqtJqaGgZfcjWTJo5h9ruv8tRTE5g7tzx0rJQNH3k7z09+gm/v3ZmZc15hwHlnhY6UsnzZF73GclO+PS9xY/W0ddOzEbOdgXOA/u7epyGPyVbbNhuatz8qdIS0aVPWMnQE2YqVlWtCR0ibfHqN5dPzUr1xacY6iOtnPpe23/fNDjk9K53OrJxhyN1XkTiW2ZDP24iISCGJ4YnhdXo+EREJqwEndM81BXOGIRERkXTRyFNERMJS21ZERCSi1M8MFIzatiIiIhFp5CkiImGpbSsiIhKR2rYiIiL5TyNPEREJK4YjTxVPEREJKpvfqpIuatuKiIhEpJGniIiEpbatiIhIRDH8qIratiIiIhFp5CkiImGpbSsiIhKR2rYiIiL5TyNPEREJS21bERGRiNS2FRERyX8aeYqISFhq26ZPpy6nhI6QNi/tfEToCGlz3KrXQ0eQrWhT1jJ0hLQ5rlW30BHS5pSy5qEjxEMMi6fatiIiIhHl7MhTREQKRAwnDKl4iohIWGrbioiI5D+NPEVEJCy1bUVERCJS21ZERCT/aeQpIiJhqW0rIiISkdq2IiIiucvMHjKzFWY2eyu3XWZmbmZt6luPiqeIiIRVW5u+S/0eAU7acqGZdQJOABY3ZCUqniIiEpZ7+i71bsqnAl9s5aY7gSuB+leCiqeIiOQRMxtkZjPqXAY14DF9gaXu/k5Dt6MJQyIiElYaJwy5+whgREPvb2ZlwFUkWrYNpuIpIiJhhZ1t+21gL+AdMwPoCMw0s17uvnxbD1LxFBGRguXu7wFtN103s0VAD3dfub3H6ZiniIiE5bXpu9TDzMYCbwD7mNkSM/t5KpE18hQRkbCy2LZ19wH13N65IevRyFNERCQijTxFRCSsBnw+M9eoeIqISFg6t62IiEj+08hTRETC0sgzPu4cdgOzP5zGq68/FzpKo3X8xSn0nDKEnlPuoNv9gylqWho6UspOPKE3c2ZP5f2507jyiotCx2mUfNqXfHq/AFhRETdMup3LHroqdJSU7fjt3TnpxZs2X87+YCT7XPh/znceD1n8qEq6FGzxfHLMMww4u95THua8Ju1a0+HCk3n7xD8w/fuXYUVFtD3jyNCxUlJUVMTQu2/k1NMGcsBBx9C//xl067Z36Fgpyad9gfx5v2xy0s9OoWL+ktAxGuWrBcv45/FX8c/jr+KFE/9E9boNfPLfM0LHKhgZL55mtquZ7Zrp7UT15uszWL1qdegYaWHFRRQ1a4IVF1Fc1pQNy7f2hQG5r1fP7ixYsIiFCxdTVVXFuHHPcvppJ4aOlZJ82hfIr/dL63a7cPCxh/LqEy+FjpI2ux21P19/vILKpds9KU7O8lpP2yVbMlI8LeE6M1sJfACUm9lnZnZNJrZXyDYu/4JPhk/g8JnDOfzdB6heU8mqKe+GjpWS9h3a8cmSis3XlyxdRvv27QImSl0+7Uu+GXjtzxh706NZ/UWbaXv2PYyPn3k9dIzUZff7PNMiUyPPS4EjgZ7u3trddwa+CxxpZpdu60F1v0qmcuPqDEXLLyWtWtDmpJ682fMi3jhoEMVlTdntrKNCxxLJSQcfeyhrPv+SRbM/Ch0lbYpKi+lwwqF8MuGt0FEKSqZm254HHF/3xLru/pGZDQQmk/jS0f+j7lfJtNupW/78WZhBOx99AOsXr6Dq8zUAfDbxLVr23IdPx78WOFl0FUuX06lj+83XO3bYnYqKbX6pQU7Lp33JJ1177Mshx/XkoN6HUNq0lOY7lvGruwYz/JK7Q0dL2e7HHswX7y1i/co1oaOkLosTfdIlU8WzdGtnpHf3z8wsvlNBc9D6pStpecjeFDVvQu26jex81AF89c6C0LFSMn3GLLp02YvOnTuxdOly+vXry3k/iecs1Xzal3wy7tbHGXfr4wB0O+w7nDyob6wLJ8CeZxwe75YtQAxb6Jlq225M8basGT7ydp6f/ATf3rszM+e8woDzzgodKSVfzZzPZ8+/SY8Xb6XnlDugqIiK0fGcCFFTU8PgS65m0sQxzH73VZ56agJz55aHjpWSfNoXyJ/3S74pbt6Udkftz5JJ00NHKTjmGTinoJnVAGu3dhPQzN3rHX3mU9v2iab7h46QNsetivlfuHmqTVnL0BHS5rhW3UJHSJtTqpqHjpA2Ayoet0ytu/KeX6ft933ZxfdlLGddGWnbuntxJtYrIiJ5KIZnGNLp+UREJKwYfqtKwZ5hSEREJFUaeYqISFhq24qIiESkj6qIiIjkP408RUQkLJ1hSEREJCK1bUVERPKfRp4iIhKUa7atiIhIRGrbioiI5D+NPEVEJCzNthUREYlIbVsREZH8p5GniIiEpdm2IiIiEaltKyIikv808hQRkbA021ZERCQitW1FRETyn0aeIiISlM5tm0YrK9eEjpA2v222JHSEtFn770dDR0ibPY/8TegIaZNP75eXmBc6Qtq822yn0BHSZkAmV57Ftq2ZPQScCqxw9/2Ty24DTgM2AguAn7r76u2tR21bEREpJI8AJ22x7EVgf3c/ECgH/ljfSlQ8RUQkrFpP36Ue7j4V+GKLZZPdvTp59U2gY33rydm2rYiIFIg0flTFzAYBg+osGuHuIyKs4mfAk/XdScVTRETyRrJQRimWm5nZn4Bq4PH67qviKSIiYeXA5zzN7AISE4n6uHu9gVQ8RUQkKA9cPM3sJOBK4PvuXtmQx2jCkIiIFAwzGwu8AexjZkvM7OfAMGBH4EUzm2Vm99e3Ho08RUQkrCyOPN19ax9ZfTDqelQ8RUQkrBieYUhtWxERkYg08hQRkbByYLZtVCqeIiISVgyLp9q2IiIiEWnkKSIiQTXgnAQ5R8VTRETCUttWREQk/2nkKSIiYcVw5KniKSIiQYU+t20q1LYVERGJSCNPEREJK4YjTxVPEREJK36ntlXbVkREJKqCLZ4nntCbObOn8v7caVx5xUWh46Rst/ZtGTl+GP+YOoanpzzOuRf2Cx0pkmuGjeb7F1zJmYP/+o3lYya+wukXX8+Zg//KkEefDpSuce4cdgOzP5zGq68/FzpKo+XL+wXy53mJ+3u/Lq/1tF2ypSCLZ1FREUPvvpFTTxvIAQcdQ//+Z9Ct296hY6WkprqGO64byplH/5iBJ/8/+v/0LL7VtXPoWA12+jGHMfzPv/nGsn+99wGvTH+Xp4ZcxT/u/jPnn358oHSN8+SYZxhw9qDQMRotn94vkD/PS9zf+99Q6+m7ZElBFs9ePbuzYMEiFi5cTFVVFePGPcvpp50YOlZKVq74nHnvlQNQubaShR8uom27XQOnarge39mbVju2+MaycS+8xs/PPJEmpaUA7LLTjiGiNdqbr89g9arVoWM0Wj69XyB/npe4v/fjLiPF08z2yMR606V9h3Z8sqRi8/UlS5fRvn27gInSo32nduy7f1femzkndJRG+bhiBW/Pm8+Pf38rP716CLM/XBQ6UkHL1/dLPon9e782jZcsydTI85lNP5jZ+IY+yMwGmdkMM5tRW7s2I8HyVfOy5gwZeTO3XnMXa7+uDB2nUapraljz1Voev+UKfnf+D7n8jgdjeeJokWzIh/e+jnn+h9X5+VsNfZC7j3D3Hu7eo6ioRf0PSFHF0uV06th+8/WOHXanomJ5xraXaSUlxQx58CYmPv0CL0+aEjpOo+22y870OexgzIwD9u5MkRmr1nwdOlbByrf3Sz7Jt/d+nGSqePo2fs4J02fMokuXvejcuROlpaX069eXCc9PDh0rZdff+ScWfvgxo//2ROgoaXHsdw9k+uzEsZxFFZ9SVV3Nzi13CJyqcOXb+yWf5M17P4Zt20ydJOEgM1tDYgTaPPkzyevu7i0ztN0GqampYfAlVzNp4hiKi4p4ZNSTzJ1bHjJSyrr3OpDTzvkB5XPnM+6lUQAMvfl+pr38RuBkDXPlkIeYMbuc1V99zXEXXsWvf3QKZx57BNfcO5ozB/+V0pISbvjt+ZhZ/SvLMcNH3s4R3+tF6112YuacV7jtlmGMHd3goxg5I5/eL5A/z0vc3/t1xfHctparx5JKmnTIzWAp2K91Ts+fimT6yzeEjpA2ex75m/rvFBMrK9fUf6eYaFMW9G/rtGrbbKfQEdLm3eVvZOwv2C/O/H7aft+3/seUrPylrdPziYhIWDE8PZ+Kp4iIBOUqniIiIhHFsHgW5BmGREREGkMjTxERCUptWxERkahiWDzVthUREYlII08REQlKbVsREZGI4lg81bYVERGJSCNPEREJKo4jTxVPEREJy+P3xQ9q24qIiESk4ikiIkF5bfou9TGzh8xshZnNrrOstZm9aGYfJv+/c33rUfEUEZGgvNbSdmmAR4CTtlj2B+Bld98beDl5fbtUPEVEpGC4+1Tgiy0W9wVGJX8eBZxR33o0YUhERIJK52xbMxsEDKqzaIS7j6jnYbu5+7Lkz8uB3erbjoqniIgE5WmcbZsslPUVy+093s3M67uf2rYiIlLoPjWz3QGS/19R3wNUPEVEJKhszrbdhueA85M/nw88W98D1LYVEZGgGjhLNi3MbCzQG2hjZkuAa4FbgHFm9nPgY6BffetR8RQRkYLh7gO2cVOfKOvJ2eK5X+s9QkeQrdjzyN+EjpA28y/sGjpC2uw0dEboCGnTttlOoSOkTdvSlqEjxILXOz0n9+Rs8RQRkcKQzbZtumjCkIiISEQaeYqISFBxHHmqeIqISFBxPOaptq2IiEhEGnmKiEhQatuKiIhElM5z22aL2rYiIiIRaeQpIiJBpfMrybJFxVNERIKqVdtWREQk/2nkKSIiQcVxwpCKp4iIBBXHj6qobSsiIhKRRp4iIhJUHE/Pp+IpIiJBqW0rIiJSADTyFBGRoPLyc56WMNDMrkle38PMemU+moiIFAJ3S9slWxrStr0POBwYkLz+FXBvxhKJiIjkuIa0bb/r7oeY2b8B3H2VmTXJcC4RESkQ+TrbtsrMigEHMLNdgRiexldERHJRHI95NqR4DgX+AbQ1sxuBs4GrM5oqw3Zr35Yb77mGXXZtjbszfvSzPD5yXOhYKcmnfQG4c9gNHH9ib1Z+9gW9jzg9dJzImva7mOL9euBff8m6238LQJNTL6Bkv554dTX++XLWPzkU1q8NnDSaE0/ozZAhf6G4qIiHHh7LrbfF88hNPr1fSpuWcudTd1DapJTi4mKmTnqNR4eMDh2rYNRbPN39cTN7G+gDGHCGu8/LeLIMqqmu4Y7rhjLvvXLKWpTxxOSHeWPqv/iofFHoaJHl074APDnmGR56YAz3DL8ldJSUVM14mar/nUjTAZdsXlZTPouNkx6F2lqanPITmvQ5i40THw0XMqKioiKG3n0jJ508gCVLlvHmG5OY8Pxk5s37MHS0yPLp/VK1oYrL+1/J+sr1FJcUc9fTQ5j+ynTm/fv90NEii+O5bRsy23YPoBKYADwHrE0ui62VKz5n3nvlAFSurWThh4to227XwKlSk0/7AvDm6zNYvWp16Bgpq/1oLl759TeW1ZTPgtrEkY6aj8uxVm0CJEtdr57dWbBgEQsXLqaqqopx457l9NNODB0rJfn2fllfuR6AkpISSkqK8TgePCRxzDNdl2xpSNt2IonjnQY0A/YCPgC+k8FcWdO+Uzv23b8r782cEzpKo+XTvuSr0l59qJ41LXSMSNp3aMcnSyo2X1+ydBm9enYPmCg98uH9UlRUxH2ThtGhc3ueHTWB92d9EDpSwWhI2/aAutfN7BDg19t7jJndQ3KC0TbW+duGBsyk5mXNGTLyZm695i7Wfl0ZOk6j5NO+5KvSPudATS3VM6eEjlLw8uX9Ultbyy9P+jUtWrbg+geupfM+e7Log49Dx4osjhOGIp+ez91nAt+t524zgLeTl9Pr/LzpslVmNsjMZpjZjC8qP40aLZKSkmKGPHgTE59+gZcnxfuXWT7tS74q6XEsJd16sH7MHaGjRFaxdDmdOrbffL1jh92pqFgeMFHj5OP7Ze2atcx6/R169u4ZOkpK4niShHpHnmb2uzpXi4BDgIpt3B0Adx9V5/GX1L1ez+NGACMADmx3eEa719ff+ScWfvgxo//2RCY3kxX5tC/5qHif7jQ55odU3ncVVG0MHSey6TNm0aXLXnTu3ImlS5fTr19fzvvJRaFjpSxf3i+tWreiurqatWvW0qRZEw49+hCeuC+eM4fjqCHHPHes83M1iWOg4yNsI+eOYHfvdSCnnfMDyufOZ9xLibo+9Ob7mfbyG4GTRZdP+wIwfOTtHPG9XrTeZSdmznmF224ZxtjRUV5uYTU99zKKv70/1qIlZVc/yMbJY2ly7NlQUkrzQdcDULu4nA3jhwdO2nA1NTUMvuRqJk0cQ3FREY+MepK5c8tDx0pJPr1fWrdtze/vvJyi4iKsqIgpE6by1stvhY6Vkji2bW17s7OSJ0f4L3e/POUNmM1090OiPi7TI09JzYr1q0NHSJv5F3YNHSFtdho6I3SEtNmvdawn839D29KWoSOkzUufvJCxCvdm+x+m7ff9YRVPZ6USb3PkaWYl7l5tZkdGXamZfcV/RpxlZrZm002Au3v+vKJERKRR4jjy3F7b9l8kjm/OMrPngL8Dm0+L4u5Pb+uB7r7jtm4TERGJu4Yc82wGfA4cy38+7+nANouniIhIQ8XxDEPbK55tkzNtZ/OformJjkeKiEhaxPGbRrZXPIuBHfhm0dxExVNERGLHzC4FLiRRx94Dfuru66OuZ3vFc5m7/yXFfCIiIg3iWx2jpZ+ZdQB+C+zn7uvMbBzwI+CRqOvaXvGMXxNaRERipza7vcwSoLmZVQFl1HPSn23Z3un5+qSyQhERkVDqnuY1eRm06TZ3XwrcDiwGlgFfuvvkVLazzZGnu3+RygpFRESiqE1jo7PuaV63ZGY7A31JfDvYauDvZjbQ3R+Lup3IJ4YXERFJJ8fSdqnHccBCd//M3atIfOTyiFQyq3iKiEihWAwcZmZlZmYkDk/OS2VFDTlJgoiISMZk63Oe7v6WmT0FzCTxRSf/Zhst3vqoeIqISFDZ+qgKgLtfC1zb2PWobSsiIhKRRp4iIhJUvp2eT0REJOPiWDzVthUREYlII08REQkqmxOG0kXFU0REgqqNX+1U21ZERCQqjTxFRCSodJ7bNltUPEVEJKjsfiNZeuRs8Zz7xeLQEWQr2pS1DB0hbbqMLA8dIW1W/7ZH6Ahpk0/Pi36P5a+cLZ4iIlIY4vg5TxVPEREJqtbid8xTs21FREQi0shTRESC0oQhERGRiOJ4zFNtWxERkYg08hQRkaDieHo+FU8REQkqjmcYUttWREQkIo08RUQkKM22FRERiSiOxzzVthUREYlII08REQkqjp/zVPEUEZGg4njMU21bERGRiDTyFBGRoOI4YUjFU0REgorjMU+1bUVERCLSyFNERIKK48hTxVNERILyGB7zVNtWREQkIo08RUQkKLVtRUREIopj8SzYtu2JJ/RmzuypvD93GldecVHoOI2ST/ty57AbmP3hNF59/bnQURot7vvStN/FlF03iuaXD928rMmpF1B25b00/93dNDv/j9CsRcCEqYn781JXPr3346Ygi2dRURFD776RU08byAEHHUP//mfQrdveoWOlJJ/2BeDJMc8w4OxBoWOkRdz3pWrGy6x/4PpvLKspn0Xl7RezbshgalcupUmfswKlS13cn5dN8um972m8ZEtBFs9ePbuzYMEiFi5cTFVVFePGPcvpp50YOlZK8mlfAN58fQarV60OHSMt4r4vtR/NxSu//saymvJZUJtostV8XI61ahMgWePE/XnZJJ/e+7WWvkt9zGwnM3vKzN43s3lmdngqmTNyzNPMrtnOze7uf83EdhuqfYd2fLKkYvP1JUuX0atn94CJUpdP+yLxUtqrD9WzpoWOUbD03k/Z3cA/3f1sM2sClKWykkxNGFq7lWVlwIXALsBWi6eZDQIGAVhxK4qK4nc8RaQQlPY5B2pqqZ45JXQUyQPZmjBkZq2Ao4ELANx9I7AxlXVlpHi6+x2bfjazHYHBwM+AJ4A7tvO4EcAIgJImHTLWvq5YupxOHdtvvt6xw+5UVCzP1OYyKp/2ReKhpMexlHTrwbq//Tl0lIKWT+/9dBbPuoOwpBHJ2gKwF/AZ8LCZHQS8DQx2960N+LYrY8c8zay1md0AvEuiSB/i7r939xWZ2mZDTZ8xiy5d9qJz506UlpbSr19fJjw/OXSslOTTvkjuK96nO02O+SHrHr4RqlL6g13SRO/9rXP3Ee7eo85lRJ2bS4BDgOHu3p1El/QPqWwnI8XTzG4DpgNfAQe4+3XuvioT20pFTU0Ngy+5mkkTxzD73Vd56qkJzJ1bHjpWSvJpXwCGj7yd5yc/wbf37szMOa8w4Lz4zebcJO770vTcy2h+8X9RtGsHyq5+kJJex9H0zF9A0+Y0H3Q9zS+9k6Zn/Sp0zMji/rxskk/v/SzOtl0CLHH3t5LXnyJRTCMz9/R3R82sFtgAVPPN/TESE4Za1reOTLZtJXVtyup96iSA+Rd2DR0hbbqMjGcB2JqVlWtCR0ib6o1LM3YG2lv3HJi23/dXfvzYdnOa2WvAhe7+gZldB7Rw9yuibidTxzwL8iMwIiISXZbPMHQx8Hhypu1HwE9TWYlOzyciIgXD3WcBPRq7HhVPEREJKo7H6FQ8RUQkqNoYlk8dmxQREYlII08REQkqjl9JpuIpIiJBxa9pq7atiIhIZBp5iohIUGrbioiIRNSQ7+HMNWrbioiIRKSRp4iIBBXHz3mqeIqISFDxK51q24qIiESmkaeIiASl2bYiIiIRxfGYp9q2IiIiEWnkKSIiQcVv3KniKSIigcXxmKfatiIiIhFp5CkiIkHFccKQiqeIiAQVv9Kp4pkVP9r9u6EjpM1LX84LHSFtVlauCR0hbbqMLA8dIW3mX9g1dIS0OeKxFaEjSIaoeIqISFBxnDCk4ikiIkF5DBu3mm0rIiISkUaeIiISlNq2IiIiEcXxoypq24qIiESkkaeIiAQVv3GniqeIiASmtq2IiEgB0MhTRESC0mxbERGRiHSSBBERkQKgkaeIiASltq2IiEhEatuKiIgUAI08RUQkqGy3bc2sGJgBLHX3U1NZh4qniIgEVetZb9sOBuYBLVNdgdq2IiJSMMysI3AKMLIx61HxFBGRoDyNFzMbZGYz6lwGbbG5u4AraWS3WG1bEREJKp3ntnX3EcCIrd1mZqcCK9z9bTPr3ZjtaOQpIiKF4kjgdDNbBDwBHGtmj6WyIhVPEREJytP433a34/5Hd+/o7p2BHwH/4+4DU8lcsMXzxBN6M2f2VN6fO40rr7godJxGs6Iibph0O5c9dFXoKI1y57AbmP3hNF59/bnQURotn15jcX9emva7mLLrRtH88qGblzU59QLKrryX5r+7m2bn/xGatQiYMLrd2rdl5Phh/GPqGJ6e8jjnXtgvdKSU1abxki0FWTyLiooYeveNnHraQA446Bj69z+Dbt32Dh2rUU762SlUzF8SOkajPTnmGQacveXx/fjJt9dY3J+Xqhkvs/6B67+xrKZ8FpW3X8y6IYOpXbmUJn3OCpQuNTXVNdxx3VDOPPrHDDz5/9H/p2fxra6dQ8eKDXd/NdXPeEKA4mlmpdne5pZ69ezOggWLWLhwMVVVVYwb9yynn3Zi6Fgpa91uFw4+9lBefeKl0FEa7c3XZ7B61erQMRot315jcX9eaj+ai1d+/Y1lNeWzoDYxVqn5uBxr1SZAstStXPE5894rB6BybSULP1xE23a7Bk6Vmlo8bZdsyUrxtIQ+ZvYgEHx41L5DOz5ZUrH5+pKly2jfvl3ARI0z8NqfMfamR/Ha+J0fMl/l22ss35X26kPN+2+HjpGy9p3ase/+XXlv5pzQUVKSrWOe6ZTR4mlmh5nZUOBj4FlgKrDvdu6/+fM5tbVrMxktbxx87KGs+fxLFs3+KHQUkVgq7XMO1NRSPXNK6CgpaV7WnCEjb+bWa+5i7deVoeMUjIx8ztPMbgLOARYDY4HrgRnuPmp7j6v7+ZySJh0y9idExdLldOrYfvP1jh12p6JieaY2l1Fde+zLIcf15KDeh1DatJTmO5bxq7sGM/ySu0NHK2j59BrLZyU9jqWkWw/W/e3PoaOkpKSkmCEP3sTEp1/g5UnxLP6grySr60KgHBgOTHD3DWaWMz3F6TNm0aXLXnTu3ImlS5fTr19fzvtJPGdDjrv1ccbd+jgA3Q77DicP6qvCmQPy6TWWr4r36U6TY35I5X1XQdXG0HFScv2df2Lhhx8z+m9PhI7SKJ79c9s2WqaK5+7A8cAA4C4zewVobmYl7l6doW02WE1NDYMvuZpJE8dQXFTEI6OeZO7c8tCxBBg+8naO+F4vWu+yEzPnvMJttwxj7OjxoWNFlm+vsbg/L03PvYzib++PtWhJ2dUPsnHyWJocezaUlNJ8UGIWbu3icjaMHx44acN173Ugp53zA8rnzmfcS4mm3tCb72fay28ETlYYLNMV38yaAqeSKKTfI/Gh1B/X97hMtm2z7Ue7fzd0hLR56ct5oSOkzcrKNaEjpE2bspS/HCLnzL+wa+gIaXPEYytCR0ibd5e/YZlad989Tk3b7/tnFz+fsZx1ZeqYZ0/gE3dfnmzZtgCaABOBVzOxTRERiac4HvPM1GzbvwEbAczsaOAWYBRQAfTN0DZFRCSG4vhRlUwd8yx29y+SP/cHRrj7eGC8mc3K0DZFRESyImPFs87koD5A3fN66WvQRERks2yeGShdMlXIxgJTzGwlsA54DcDMugBfZmibIiISQ/qoSpK732hmL5P4yMpk/8+/TBFwcSa2KSIiki0Za6G6+5tbWRbfD7qJiEhGxHG2rY4/iohIUNmcJZsuBfl9niIiIo2hkaeIiASl2bYiIiIRxXG2rdq2IiIiEWnkKSIiQaltKyIiEpFm24qIiBQAjTxFRCSo2hhOGFLxFBGRoOJXOtW2FRERiUwjTxERCUqzbUVERCKKY/FU21ZERCQijTxFRCSoOJ6eL2eL536t9wgdIW2W164NHSFt2jbbKXSEtFlZuSZ0BNmK654qCx0hbYZ6x9ARYkFtWxERkQKQsyNPEREpDHE8PZ+Kp4iIBBXHY55q24qIiESkkaeIiAQVxwlDKp4iIhKU2rYiIiI5ysw6mdkrZjbXzOaY2eBU16WRp4iIBJXFtm01cJm7zzSzHYG3zexFd58bdUUqniIiElS2Pqri7suAZcmfvzKzeUAHIHLxVNtWRETyhpkNMrMZdS6DtnG/zkB34K1UtqORp4iIBFWbxglD7j4CGLG9+5jZDsB44BJ3T+k8nSqeIiISVDbPMGRmpSQK5+Pu/nSq61HbVkRECoKZGfAgMM/dhzRmXRp5iohIUOls29bjSOA84D0zm5VcdpW7T4q6IhVPEREJKouzbacBlo51qW0rIiISkUaeIiISVBbbtmmj4ikiIkHF8fs81bYVERGJSCNPEREJSm1bERGRiNS2FRERKQAaeYqISFDutaEjRFaQxXO39m258Z5r2GXX1rg740c/y+Mjx4WOlZLSpqXc+dQdlDYppbi4mKmTXuPRIaNDx0pJPj0vACee0JshQ/5CcVERDz08lltvuzd0pJTdOewGjj+xNys/+4LeR5weOk6jXDVtKBu+XkdtbS211bXcffqfQkdKWcdfnMLuP+4DOF/PW8wHg++jdkNV6FiRZfH7PNOmIItnTXUNd1w3lHnvlVPWoownJj/MG1P/xUfli0JHi6xqQxWX97+S9ZXrKS4p5q6nhzD9lenM+/f7oaNFlk/PS1FREUPvvpGTTh7AkiXLePONSUx4fjLz5n0YOlpKnhzzDA89MIZ7ht8SOkpaDB9wA5Wrvgodo1GatGtNhwtPZvpRl1K7fiP7jbiUtmccyfInXw0drSAU5DHPlSs+Z9575QBUrq1k4YeLaNtu18CpUre+cj0AJSUllJQU4zGcuQb59bz06tmdBQsWsXDhYqqqqhg37llOP+3E0LFS9ubrM1i9anXoGLIFKy6iqFkTrLiI4rKmbFj+RehIKXH3tF2yJSMjTzObAN8YhzuwEnjF3R/LxDZT1b5TO/bdvyvvzZwTOkrKioqKuG/SMDp0bs+zoybw/qwPQkdqtLg/L+07tOOTJRWbry9ZuoxePbsHTCSbuTNo9B/BnTfGvMxbY/8ndKKUbFz+BZ8Mn8DhM4dTs24jq6a8w6op74aOlRK1bf/j9q0saw0MNLP93f0PW3tQ8hu/BwF02HEvWpftlqF4Cc3LmjNk5M3ces1drP26MqPbyqTa2lp+edKvadGyBdc/cC2d99mTRR98HDpWyvLleZHcNOzs61jz6Sp22KUlgx67is8WVPDRv+J3mKOkVQvanNSTN3teRPWXa/nOyN+x21lH8en410JHKwgZadu6+5StXP4B9ANO2s7jRrh7D3fvkenCWVJSzJAHb2Li0y/w8qQpGd1Wtqxds5ZZr79Dz949Q0dJWb48LxVLl9OpY/vN1zt22J2KiuUBE8kmaz5dBcDXn69h9gvT6XTQtwMnSs3ORx/A+sUrqPp8DV5dw2cT36Jlz31Cx0pJHNu2WT3m6e412dze9lx/559Y+OHHjP7bE6GjNEqr1q1o0bIFAE2aNeHQow9h8fxPAqdKXb48L9NnzKJLl73o3LkTpaWl9OvXlwnPTw4dq+A1ad6Upi2abf6561EHsrx8SeBUqVm/dCUtD9mbouZNANj5qAOo/DCe+1LrnrZLtmTqmGfrrSzeGfgJEPwgVvdeB3LaOT+gfO58xr00CoChN9/PtJffCJwsutZtW/P7Oy+nqLgIKypiyoSpvPXyW6FjpSSfnpeamhoGX3I1kyaOobioiEdGPcncueWhY6Vs+MjbOeJ7vWi9y07MnPMKt90yjLGjx4eOFdkObVpxwYjfAVBUXMy/n/1fPpjyTuBUqflq5nw+e/5Nerx4K15Tw1fvLaJi9EuhYxUMy8Qw18wWkpgktOlLR2uBz4FXgRvcfU196ziw3eHxO4K8DW1LW4aOkDYrqup96mJj7heLQ0dImzZl+fMaG7jTwaEjpM2p66pDR0ib3p/+PS1fIr017Xbqlrbf98tXz8tYzroyNWGoP/CJuy8DMLPzgbOAZhncpoiIxFAcP16XqWOe9wMbAMzsaOBmYBTwJTAiQ9sUEZEYqsXTdsmWTI0Ci91906d1+wMj3H08MN7MZmVomyIiIlmRseJpZiXuXg30IfnZzQxvU0REYiiObdtMFbKxwBQzWwmsA14DMLMuJFq3IiIigL4MezN3v9HMXgZ2Byb7f/6sKAIuzsQ2RUREsiVjLVR3f3Mry+L7QTcREckItW1FREQiiuOJ4QvyK8lEREQaQyNPEREJSm1bERGRiOI421ZtWxERkYg08hQRkaA8hhOGVDxFRCQotW1FREQKgEaeIiISlGbbioiIRBTHY55q24qIiESkkaeIiAQVx7atRp4iIhKUu6ftUh8zO8nMPjCz+Wb2h1Qzq3iKiEhBMLNi4F7gB8B+wAAz2y+Vdal4iohIUJ7GSz16AfPd/SN33wg8AfRNJXPOHvN8d/kblo3tmNkgdx+RjW1lmvYlN2lfcpP2JXdUb1yatt/3ZjYIGFRn0Yg6/zYdgE/q3LYE+G4q29HI85v/yHGnfclN2pfcpH3JQ+4+wt171Llk5I8KFU8RESkUS4FOda53TC6LTMVTREQKxXRgbzPby8yaAD8CnktlRTl7zDOLYnucYCu0L7lJ+5KbtC8Fxt2rzew3wAtAMfCQu89JZV0Wxw+nioiIhKS2rYiISEQqniIiIhEVbPE0szPMzM1s39BZGsPMasxslpnNMbN3zOwyM4vt81pnfzZdOofOlAoz+3qL6xeY2bBQeRoj+T65o871y83suoCRIjOzPyXfI+8mX1ffTS4vMbPPzOyW0Bkbamv7YmaLzKxNnfv0NrPnQ+bMd4U8YWgAMC35/2sDZ2mMde5+MICZtQXGAC2J7z5t3h/JGRuAH5rZze6+MnSYqMzscOBU4BB335AsMk2SNx8PlAPnmNkfPccngdSzL5JFsR2hNIaZ7QB8D/g5ianKecHdV5D4sPRvzCwrZ2iSglBNYjbnpaGDpGh3YKW7bwBw95XuXpG8bQBwN7AYODxQvii2ty+SRQVZPEmcy/Cf7l4OfG5mh4YOlC7u/hGJKdhtQ2dJUfM6Ldt/hA7TCHX3Yxbwl9CBGule4FwzaxU6SAomA53MrNzM7jOz7wOYWTPgOGACMJZEIc11W90Xyb5CLZ4DSJwQmOT/4/CmKRTr3P3g5OXM0GEaoe5+HAxcEzpQY7j7GuBR4Lehs0Tl7l8Dh5LoynwGPGlmF5Bof77i7uuA8cAZyW/dyFnb2ZettZtzugUddwV3zNPMWgPHAgeYmZMYpbmZXZHrxzsawsy+BdQAK0JnkbxzFzATeDhwjsjcvQZ4FXjVzN4Dzgc2At8zs0XJu+1C4nfDiyEyNtQ29uVzYGdg0zHp1nV+lgwoxJHn2cBod9/T3Tu7eydgIXBU4FyNZma7AvcDw/LhDwHJLe7+BTCOxFyB2DCzfcxs7zqLDiYxajsK2CP5e6AzcBE53oXaxr58TKKYnpe8TzEwEHgl2/kKScGNPEm8Of5ri2Xjk8unZj9OozVPHlMrJTGxYzQwJGgiyWd3AL8JHSKiHYB7zGwnEu+R+cCzQNmmiTdJzwK3mlnTLZbnkq3tyyCgChhuZu8ABvwTeCxUyEKg0/OJiIhEVIhtWxERkUZR8RQREYlIxVNERCQiFU8REZGIVDxFREQiUvEUSVGdb4CZbWZ/N7OyRqzrETM7O535RCRzVDxFUrfpFHz7kzhbzS/r3mhmhfg5apGCoOIpkh6vAV2S36P4mpk9B8w1s2Izu83Mpie/f/EXAJYwzMw+MLOXiO+J/EUKkv4yFmmk5AjzByTO6gJwCLC/uy80s0HAl+7e08yaAv9rZpOB7sA+wH7AbsBc4KHspxeRVKh4iqRu06kRITHyfBA4AviXuy9MLj8BOLDO8cxWwN7A0cDY5Em+K8zsf7IXW0QaS8VTJHXrkl83tlnyO8jX1l0EXOzuL2xxv5Mznk5EMkbHPEUy6wXgV2ZWCmBmXc2sBYkvIeifPCa6O3BMyJAiEo1GniKZNRLoDMy0xLD0M+AM4B8kvjtyLrAYeCNQPhFJgb5VRUREJCK1bUVERCJS8RQREYlIxVNERCQiFU8REZGIVDxFREQiUvEUERGJSMVTREQkov8PO3MX6ga0Oe4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true_all, y_pred_all)\n",
    "\n",
    "plt.figure(figsize=(8, 7))\n",
    "heatmap(cm, annot=True, xticklabels=idx_to_label.values(), yticklabels=idx_to_label.values())\n",
    "plt.xlabel('Pred')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "histplot(y_true_all, bins=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse graph of human body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
